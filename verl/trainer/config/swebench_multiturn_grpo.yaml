hydra:
  searchpath:
    - file://examples/sglang_multiturn/config
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  train_files: ${oc.env:SWEBENCH_TRAIN,${oc.env:HOME}/data/swebench_mini/rl/train.parquet}
  val_files: ${oc.env:SWEBENCH_VAL,${oc.env:HOME}/data/swebench_mini/rl/val.parquet}
  max_prompt_length: ${oc.env:SWEBENCH_MAX_PROMPT_LENGTH,4096}
  max_response_length: ${oc.env:SWEBENCH_MAX_RESPONSE_LENGTH,1024}
  return_raw_chat: True
  train_batch_size: ${oc.env:SWEBENCH_TRAIN_BATCH_SIZE,1024}
  train_max_samples: ${oc.env:SWEBENCH_TRAIN_MAX_SAMPLES,-1}
  val_max_samples: ${oc.env:SWEBENCH_VAL_MAX_SAMPLES,-1}

algorithm:
  adv_estimator: grpo
  use_kl_in_reward: False

actor_rollout_ref:
  hybrid_engine: True
  model:
    path: ${oc.env:SWEBENCH_MODEL,allenai/OLMo-2-1124-7B-Instruct}
    use_remove_padding: True
  actor:
    strategy: fsdp
    fsdp_config:
      model_dtype: bf16
    optim:
      lr: 5e-7
    ppo_mini_batch_size: ${oc.env:SWEBENCH_PPO_MINI_BATCH,8}
    ppo_micro_batch_size_per_gpu: 1
    ppo_max_token_len_per_gpu: 32768  
    use_dynamic_bsz: True
  rollout:
    name: sglang
    n: 1
    tensor_model_parallel_size: 1
    gpu_memory_utilization: 0.7  # Increased from 0.4 for better KV cache and throughput
    max_num_batched_tokens: 32768  # Increased from default 8192 for better batching
    multi_turn:
      enable: True
      max_assistant_turns: 6
      max_user_turns: 6
      tool_config_path: ${oc.env:SWEBENCH_TOOL_CONFIG,examples/sglang_multiturn/config/tool_config/swebench_tool_config.yaml}
  ref:
    log_prob_micro_batch_size_per_gpu: 1

critic:
  enable: False

reward_model:
  enable: False

trainer:
  n_gpus_per_node: ${oc.env:SWEBENCH_NUM_GPUS,1}
  nnodes: 1
  total_training_steps: 100
  save_freq: 50
  logger: console
  val_before_train: False

transfer_queue:
  enable: False
